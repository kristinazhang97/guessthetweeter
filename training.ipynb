{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas dataframe\n",
    "data = pd.read_pickle(\"processed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data into X and y data\n",
    "# split using column names\n",
    "X = data.iloc[:, 0:-2].to_numpy()\n",
    "y = data.iloc[:, -1].to_numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 17:59:37.884841: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# shuffling with tensorflow\n",
    "# indices = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n",
    "indices = tf.range(start=0, limit=tf.shape(X)[0])\n",
    "shuffled_indices = tf.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_a = tf.gather(X, shuffled_indices)\n",
    "shuffled_b = tf.gather(y, shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_shuffled = np.array(shuffled_a)\n",
    "y_shuffled = np.array(shuffled_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recent_search_milo import transpose_tweeters\n",
    "\n",
    "transposed_y_shuffled = np.empty(shape=(len(y_shuffled)))\n",
    "\n",
    "# change the y-shuffled's to 0-25\n",
    "for i in range(len(y_shuffled)):\n",
    "    transposed_y_shuffled[i] = transpose_tweeters[y_shuffled[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3. 12. 14. ...  8. 15.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(transposed_y_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate training and testing data\n",
    "l = int(len(X_shuffled) * 0.75)\n",
    "\n",
    "X_train = X_shuffled[:l]\n",
    "X_test = X_shuffled[l:]\n",
    "y_train = transposed_y_shuffled[:l]\n",
    "y_test = transposed_y_shuffled[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for t in X_train:\n",
    "    if len(t) < 14743:\n",
    "        print(counter)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a logistic regression\n",
    "log_reg = LogisticRegression(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milo/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression, took about 6.5 minutes to train last time\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate score\n",
    "score = log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5716667824636976\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_101 (Dense)           (None, 60)                884640    \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 30)                1830      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 25)                775       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 887,245\n",
      "Trainable params: 887,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milo/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape = (14743,), activation = \"relu\"))\n",
    "model.add(Dense(30, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(Dense(25, activation = \"softmax\"))\n",
    "model.compile(Adam(lr = 0.01), \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4815 - accuracy: 0.8554\n",
      "Epoch 2/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4883 - accuracy: 0.8546\n",
      "Epoch 3/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4975 - accuracy: 0.8547\n",
      "Epoch 4/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4682 - accuracy: 0.8590\n",
      "Epoch 5/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4711 - accuracy: 0.8586\n",
      "Epoch 6/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4749 - accuracy: 0.8595\n",
      "Epoch 7/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4731 - accuracy: 0.8583\n",
      "Epoch 8/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4785 - accuracy: 0.8582\n",
      "Epoch 9/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4695 - accuracy: 0.8595\n",
      "Epoch 10/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4646 - accuracy: 0.8592\n",
      "Epoch 11/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4720 - accuracy: 0.8600\n",
      "Epoch 12/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4724 - accuracy: 0.8604\n",
      "Epoch 13/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4628 - accuracy: 0.8624\n",
      "Epoch 14/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4707 - accuracy: 0.8605\n",
      "Epoch 15/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4510 - accuracy: 0.8626\n",
      "Epoch 16/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4592 - accuracy: 0.8635\n",
      "Epoch 17/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4719 - accuracy: 0.8597\n",
      "Epoch 18/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4637 - accuracy: 0.8619\n",
      "Epoch 19/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4559 - accuracy: 0.8644\n",
      "Epoch 20/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4642 - accuracy: 0.8639\n",
      "Epoch 21/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4604 - accuracy: 0.8639\n",
      "Epoch 22/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4712 - accuracy: 0.8631\n",
      "Epoch 23/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4525 - accuracy: 0.8628\n",
      "Epoch 24/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4607 - accuracy: 0.8645\n",
      "Epoch 25/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4588 - accuracy: 0.8644\n",
      "Epoch 26/100\n",
      "1350/1350 [==============================] - 6s 5ms/step - loss: 0.4532 - accuracy: 0.8653\n",
      "Epoch 27/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4546 - accuracy: 0.8653\n",
      "Epoch 28/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4764 - accuracy: 0.8652\n",
      "Epoch 29/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4550 - accuracy: 0.8657\n",
      "Epoch 30/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4507 - accuracy: 0.8684\n",
      "Epoch 31/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4559 - accuracy: 0.8653\n",
      "Epoch 32/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4473 - accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4391 - accuracy: 0.8689\n",
      "Epoch 34/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4467 - accuracy: 0.8692\n",
      "Epoch 35/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4512 - accuracy: 0.8682\n",
      "Epoch 36/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4533 - accuracy: 0.8654\n",
      "Epoch 37/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4487 - accuracy: 0.8668\n",
      "Epoch 38/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4609 - accuracy: 0.8672\n",
      "Epoch 39/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.8691\n",
      "Epoch 40/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4443 - accuracy: 0.8698\n",
      "Epoch 41/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4412 - accuracy: 0.8688\n",
      "Epoch 42/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4519 - accuracy: 0.8686\n",
      "Epoch 43/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4547 - accuracy: 0.8692\n",
      "Epoch 44/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4402 - accuracy: 0.8713\n",
      "Epoch 45/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4558 - accuracy: 0.8682\n",
      "Epoch 46/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.8707\n",
      "Epoch 47/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4496 - accuracy: 0.8697\n",
      "Epoch 48/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4535 - accuracy: 0.8700\n",
      "Epoch 49/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.8711\n",
      "Epoch 50/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.8704\n",
      "Epoch 51/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4536 - accuracy: 0.8688\n",
      "Epoch 52/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4472 - accuracy: 0.8699\n",
      "Epoch 53/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4373 - accuracy: 0.8708\n",
      "Epoch 54/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4357 - accuracy: 0.8706\n",
      "Epoch 55/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4399 - accuracy: 0.8713\n",
      "Epoch 56/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.8732\n",
      "Epoch 57/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4331 - accuracy: 0.8736\n",
      "Epoch 58/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.8713\n",
      "Epoch 59/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4359 - accuracy: 0.8716\n",
      "Epoch 60/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4424 - accuracy: 0.8705\n",
      "Epoch 61/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4456 - accuracy: 0.8718\n",
      "Epoch 62/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4297 - accuracy: 0.8756\n",
      "Epoch 63/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4419 - accuracy: 0.8713\n",
      "Epoch 64/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4414 - accuracy: 0.8713\n",
      "Epoch 65/100\n",
      "1350/1350 [==============================] - 7s 6ms/step - loss: 0.4418 - accuracy: 0.8718\n",
      "Epoch 66/100\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4337 - accuracy: 0.8735\n",
      "Epoch 67/100\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4300 - accuracy: 0.8734\n",
      "Epoch 68/100\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4511 - accuracy: 0.8720\n",
      "Epoch 69/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4393 - accuracy: 0.8749\n",
      "Epoch 70/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4267 - accuracy: 0.8741\n",
      "Epoch 71/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4308 - accuracy: 0.8741\n",
      "Epoch 72/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4327 - accuracy: 0.8755\n",
      "Epoch 73/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4324 - accuracy: 0.8748\n",
      "Epoch 74/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4309 - accuracy: 0.8732\n",
      "Epoch 75/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4377 - accuracy: 0.8735\n",
      "Epoch 76/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4358 - accuracy: 0.8717\n",
      "Epoch 77/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4380 - accuracy: 0.8722\n",
      "Epoch 78/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4358 - accuracy: 0.8731\n",
      "Epoch 79/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.8729\n",
      "Epoch 80/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4555 - accuracy: 0.8732\n",
      "Epoch 81/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4359 - accuracy: 0.8747\n",
      "Epoch 82/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4271 - accuracy: 0.8744\n",
      "Epoch 83/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4356 - accuracy: 0.8740\n",
      "Epoch 84/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4347 - accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4244 - accuracy: 0.8770\n",
      "Epoch 86/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4304 - accuracy: 0.8757\n",
      "Epoch 87/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4261 - accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.8749\n",
      "Epoch 89/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4258 - accuracy: 0.8755\n",
      "Epoch 90/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4319 - accuracy: 0.8728\n",
      "Epoch 91/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4282 - accuracy: 0.8743\n",
      "Epoch 92/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.8744\n",
      "Epoch 93/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4435 - accuracy: 0.8746\n",
      "Epoch 94/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4317 - accuracy: 0.8738\n",
      "Epoch 95/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4221 - accuracy: 0.8746\n",
      "Epoch 96/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4320 - accuracy: 0.8739\n",
      "Epoch 97/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4219 - accuracy: 0.8751\n",
      "Epoch 98/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4137 - accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4272 - accuracy: 0.8762\n",
      "Epoch 100/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4219 - accuracy: 0.8757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8f6aee1fd0>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleantext as ct\n",
    "\n",
    "def predict_tweeter(tweet: str, model: Sequential) -> str:\n",
    "    # clean the tweet\n",
    "    cleaned = ct.clean_tweet(tweet)\n",
    "    # get vocabulary\n",
    "    vocab = ct.get_word_set()\n",
    "    # get counterizer\n",
    "    cv = CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "    # get a word vector for it\n",
    "    wv = ct.get_word_vector(tweet, cv, vocab)\n",
    "\n",
    "    # predict on the word vector\n",
    "    prediction = model.predict(wv)\n",
    "\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f24fb1fbaf4de5d04d0c3b0d02603e78f9463bf4271da52643be3ab307db3b7d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
