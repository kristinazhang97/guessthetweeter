{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas dataframe\n",
    "data = pd.read_pickle(\"processed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to an integer representation: 0 rather than '0'\n",
    "data = data.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data into X and y data\n",
    "# split using column names\n",
    "X = data.iloc[:, 0:-2].to_numpy()\n",
    "y = data.iloc[:, -1].to_numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 17:59:37.884841: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# shuffling with tensorflow\n",
    "# indices = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n",
    "indices = tf.range(start=0, limit=tf.shape(X)[0])\n",
    "shuffled_indices = tf.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data for presentation to the ML models\n",
    "shuffled_a = tf.gather(X, shuffled_indices)\n",
    "shuffled_b = tf.gather(y, shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change shuffled arrays to numpy arrays\n",
    "X_shuffled = np.array(shuffled_a)\n",
    "y_shuffled = np.array(shuffled_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recent_search_milo import transpose_tweeters\n",
    "\n",
    "transposed_y_shuffled = np.empty(shape=(len(y_shuffled)))\n",
    "\n",
    "# change the y-shuffled's to values 0-25 rather than their respective id's\n",
    "for i in range(len(y_shuffled)):\n",
    "    transposed_y_shuffled[i] = transpose_tweeters[y_shuffled[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate training and testing data\n",
    "l = int(len(X_shuffled) * 0.75)\n",
    "\n",
    "X_train = X_shuffled[:l]\n",
    "X_test = X_shuffled[l:]\n",
    "y_train = transposed_y_shuffled[:l]\n",
    "y_test = transposed_y_shuffled[l:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a logistic regression\n",
    "log_reg = LogisticRegression(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milo/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression, took about 6.5 minutes to train last time\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy of logistic regression: 0.5716667824636976\n"
     ]
    }
   ],
   "source": [
    "# evaluate score\n",
    "score = log_reg.score(X_test, y_test)\n",
    "print(f\"test accuracy of logistic regression: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_113 (Dense)           (None, 60)                884640    \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 30)                1830      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 25)                775       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 887,245\n",
      "Trainable params: 887,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape = (14743,), activation = \"relu\"))\n",
    "model.add(Dense(30, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(Dense(25, activation = \"softmax\"))\n",
    "model.compile(Adam(lr = 0.01), \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4171 - accuracy: 0.8814\n",
      "Epoch 2/25\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4147 - accuracy: 0.8799\n",
      "Epoch 3/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4123 - accuracy: 0.8808\n",
      "Epoch 4/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4340 - accuracy: 0.8785\n",
      "Epoch 5/25\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4154 - accuracy: 0.8798\n",
      "Epoch 6/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4111 - accuracy: 0.8809\n",
      "Epoch 7/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4144 - accuracy: 0.8801\n",
      "Epoch 8/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4295 - accuracy: 0.8802\n",
      "Epoch 9/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4218 - accuracy: 0.8798\n",
      "Epoch 10/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4425 - accuracy: 0.8792\n",
      "Epoch 11/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4244 - accuracy: 0.8802\n",
      "Epoch 12/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4223 - accuracy: 0.8792\n",
      "Epoch 13/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4079 - accuracy: 0.8803\n",
      "Epoch 14/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4170 - accuracy: 0.8791\n",
      "Epoch 15/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4157 - accuracy: 0.8784\n",
      "Epoch 16/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4164 - accuracy: 0.8810\n",
      "Epoch 17/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4236 - accuracy: 0.8789\n",
      "Epoch 18/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4196 - accuracy: 0.8816\n",
      "Epoch 19/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4208 - accuracy: 0.8811\n",
      "Epoch 20/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4148 - accuracy: 0.8805\n",
      "Epoch 21/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4137 - accuracy: 0.8796\n",
      "Epoch 22/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4129 - accuracy: 0.8818\n",
      "Epoch 23/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4352 - accuracy: 0.8789\n",
      "Epoch 24/25\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4162 - accuracy: 0.8798\n",
      "Epoch 25/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4033 - accuracy: 0.8814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f911e982220>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, verbose=1, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.484541\n",
      "Loss: 25.118053\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))\n",
    "print('Loss: %f' % (loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of most popular twitter accounts\n",
    "most_popular_tweeters = {813286 : \"@barackobama\", 27260086 : \"@justinbieber\", 21447363 : \"@katyperry\", \n",
    "    79293791 : \"@rihanna\", 14230524 : \"@ladygaga\", 44196397 : \"@elonmusk\", 15846407 : \"@theellenshow\", \n",
    "    10228272 : \"@youtube\", 25365536 : \"@kimkardashian\", 23375688 : \"@selenagomez\", 428333 : \"@cnnbrk\", \n",
    "    783214 : \"@twitter\", 759251 : \"@cnn\", 16409683 : \"@britneyspears\", 11348282 : \"@nasa\", 21111883 : \"@ddlovato\", # 16\n",
    "    807095 : \"@nytimes\", 15485441 : \"@jimmyfallon\", 23083404 : \"@kingjames\", 5402612 : \"@bbcbreaking\", # 20\n",
    "    268414482 : \"@mileycyrus\", 105119490 : \"@niallofficial\", 96951800 : \"@fcbarcelona\", 627673190 : \"@championsleague\", \n",
    "    26257166 : \"@sportscenter\"}\n",
    "\n",
    "transpose_tweeters = {813286 : 0, 27260086 : 1, 21447363 : 2, \n",
    "    79293791 : 3, 14230524 : 4, 44196397 : 5, 15846407 : 6, \n",
    "    10228272 : 7, 25365536 : 8, 23375688 : 9, 428333 : 10, \n",
    "    783214 : 11, 759251 : 12, 16409683 : 13, 11348282 : 14, 21111883 : 15, # 16\n",
    "    807095 : 16, 15485441 : 17, 23083404 : 18, 5402612 : 19, # 20\n",
    "    268414482 : 20, 105119490 : 21, 96951800 : 22, 627673190 : 23, \n",
    "    26257166 : 24}\n",
    "\n",
    "\n",
    "reverse_transpose_tweeters = {0: 813286, 1: 27260086, 2: 21447363, \n",
    "    3:79293791, 4:14230524, 5:44196397, 6:15846407, \n",
    "    7:10228272, 8:25365536, 9:23375688, 10:428333, \n",
    "    11:783214, 12:759251, 13:16409683, 14:11348282, 15:21111883, # 16\n",
    "    16:807095, 17:15485441, 18:23083404, 19:5402612, # 20\n",
    "    20:268414482, 21:105119490, 22:96951800, 23:627673190, \n",
    "    24:26257166}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleantext as ct\n",
    "import recent_search_milo as rsm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import pprint\n",
    "\n",
    "def predict_tweeter(tweet: str, model: Sequential) -> str:\n",
    "    '''\n",
    "    takes a tweet string from one of the twenty-five tweeters\n",
    "    returns a dictionary of the tweeters' handles and their model scores\n",
    "    prints the top three accounts and their scores\n",
    "    '''\n",
    "    \n",
    "    # clean the tweet\n",
    "    cleaned = ct.clean_tweet(tweet)\n",
    "    # get vocabulary\n",
    "    vocab = ct.get_word_set()\n",
    "    # get counterizer\n",
    "    cv = CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "    # get a word vector for it\n",
    "    wv = ct.get_word_vector(cleaned, cv)\n",
    "\n",
    "    # predict on the word vector\n",
    "    prediction = model.predict(wv)\n",
    "\n",
    "    # create a dictionary to hold the scores\n",
    "    pred_dict = dict.fromkeys(reverse_transpose_tweeters.keys())\n",
    "\n",
    "    # iterate through the result\n",
    "    for i in range(len(prediction[0])):\n",
    "        pred_dict[i] = prediction[0][i]\n",
    "\n",
    "    # add @ keys to the dictionary\n",
    "    for key in [k for k in pred_dict.keys()]:\n",
    "        k = reverse_transpose_tweeters[key]\n",
    "        k = most_popular_tweeters[k]\n",
    "        v = pred_dict.pop(key)\n",
    "\n",
    "        pred_dict.update({k : v})\n",
    "\n",
    "    # create a counter object of the prediction dictionary\n",
    "    cr = Counter(pred_dict)\n",
    "    # get the three most likely tweeters\n",
    "    highest = cr.most_common(5)\n",
    "\n",
    "    pprint.pprint(highest)\n",
    "\n",
    "    return pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@barackobama', 1.0), ('@justinbieber', 0.0), ('@katyperry', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from obama\n",
    "pd1 = predict_tweeter(\"Last week, I spoke with some of the young activists who have already recognized the problem \"\n",
    "    \"that disinformation poses to our communities and are doing their part to fix it. Take a look at our conversation:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@selenagomez', 1.0),\n",
      " ('@rihanna', 2.9733737e-18),\n",
      " ('@jimmyfallon', 3.513508e-37)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from rihanna\n",
    "pd2 = predict_tweeter(\"Twake up and smell the billboard NYC!!!! \\n\\na wise woman once said,\" \n",
    "\" ‚Äúsmell however the f*ck you want‚Äù üíÅüèø‚Äç‚ôÄÔ∏è, \\nand that wise woman is also here with great news‚Ä¶ \"\n",
    "\"#FENTYPARFUM is finally back baby @ http://ri-hanna.io/fentyparfum\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@nytimes', 0.99999356),\n",
      " ('@mileycyrus', 3.3356807e-06),\n",
      " ('@ddlovato', 1.6588468e-06)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from elon musk\n",
    "pd3 = predict_tweeter(\"Since I‚Äôve been asked a lot:\\nBuy stock in several companies that make products \"\n",
    "\"& services that *you* believe in.\\nOnly sell if you think their products & services are trending worse. \"\n",
    "\"Don‚Äôt panic when the market does.\\nThis will serve you well in the long-term.\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@cnnbrk', 1.0), ('@nytimes', 3.9457587e-10), ('@cnn', 1.3161707e-12)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from cnnbrk\n",
    "pd4 = predict_tweeter(\"A former Philadelphia police officer who fatally shot a 12-year-old boy in the back in March has been charged with first-degree murder, District Attorney Larry Krasner announced Monday.\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@jimmyfallon', 0.28683314),\n",
      " ('@kingjames', 0.26641595),\n",
      " ('@theellenshow', 0.15249594)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from rihanna\n",
    "pd5 = predict_tweeter(\"My very first #NationalHeroesDay as a National Hero of my country Barbados! üáßüáßüáßüáßüáßüáß What an absolute honor to be amongst such great men and women who have come before me and held this title in commitment to our nation!\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@theellenshow', 0.7618925),\n",
      " ('@kingjames', 0.23275675),\n",
      " ('@jimmyfallon', 0.005350794)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from lebron james\n",
    "pd6 = predict_tweeter(\"Wow it's been awhile since I've seen that footage. Weight of the world on the shoulders on #ThekidfromAKRONü§¥üèæ\", model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f24fb1fbaf4de5d04d0c3b0d02603e78f9463bf4271da52643be3ab307db3b7d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
