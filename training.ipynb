{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.optimizers import SGD, Adam, Adadelta, RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the pandas dataframe\n",
    "data = pd.read_pickle(\"processed_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# change to an integer representation: 0 rather than '0'\n",
=======
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
    "data = data.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate the data into X and y data\n",
    "# split using column names\n",
    "X = data.iloc[:, 0:-2].to_numpy()\n",
    "y = data.iloc[:, -1].to_numpy().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-02 17:59:37.884841: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# shuffling with tensorflow\n",
    "# indices = tf.range(start=0, limit=tf.shape(X)[0], dtype=tf.int32)\n",
    "indices = tf.range(start=0, limit=tf.shape(X)[0])\n",
    "shuffled_indices = tf.random.shuffle(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# shuffle the data for presentation to the ML models\n",
=======
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
    "shuffled_a = tf.gather(X, shuffled_indices)\n",
    "shuffled_b = tf.gather(y, shuffled_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# change shuffled arrays to numpy arrays\n",
=======
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
    "X_shuffled = np.array(shuffled_a)\n",
    "y_shuffled = np.array(shuffled_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recent_search_milo import transpose_tweeters\n",
    "\n",
    "transposed_y_shuffled = np.empty(shape=(len(y_shuffled)))\n",
    "\n",
<<<<<<< HEAD
    "# change the y-shuffled's to values 0-25 rather than their respective id's\n",
=======
    "# change the y-shuffled's to 0-25\n",
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
    "for i in range(len(y_shuffled)):\n",
    "    transposed_y_shuffled[i] = transpose_tweeters[y_shuffled[i]]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
=======
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3. 12. 14. ...  8. 15.  3.]\n"
     ]
    }
   ],
   "source": [
    "print(transposed_y_shuffled)"
   ]
  },
  {
   "cell_type": "code",
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate training and testing data\n",
    "l = int(len(X_shuffled) * 0.75)\n",
    "\n",
    "X_train = X_shuffled[:l]\n",
    "X_test = X_shuffled[l:]\n",
    "y_train = transposed_y_shuffled[:l]\n",
    "y_test = transposed_y_shuffled[l:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 230,
=======
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for t in X_train:\n",
    "    if len(t) < 14743:\n",
    "        print(counter)\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a logistic regression\n",
    "log_reg = LogisticRegression(max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 231,
=======
   "execution_count": 29,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milo/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
<<<<<<< HEAD
     "execution_count": 231,
=======
     "execution_count": 29,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the logistic regression, took about 6.5 minutes to train last time\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 234,
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate score\n",
    "score = log_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "test accuracy of logistic regression: 0.5716667824636976\n"
=======
      "0.5716667824636976\n"
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "# evaluate score\n",
    "score = log_reg.score(X_test, y_test)\n",
    "print(f\"test accuracy of logistic regression: {score}\")"
=======
    "print(score)"
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 214,
=======
   "execution_count": 104,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Model: \"sequential_45\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_113 (Dense)           (None, 60)                884640    \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 30)                1830      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 25)                775       \n",
=======
      "Model: \"sequential_42\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_101 (Dense)           (None, 60)                884640    \n",
      "                                                                 \n",
      " dense_102 (Dense)           (None, 30)                1830      \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (None, 25)                775       \n",
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 887,245\n",
      "Trainable params: 887,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
<<<<<<< HEAD
=======
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milo/opt/anaconda3/envs/data_science/lib/python3.9/site-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(60, input_shape = (14743,), activation = \"relu\"))\n",
    "model.add(Dense(30, activation = \"relu\"))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(Dense(25, activation = \"softmax\"))\n",
    "model.compile(Adam(lr = 0.01), \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 220,
=======
   "execution_count": 110,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "Epoch 1/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4171 - accuracy: 0.8814\n",
      "Epoch 2/25\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4147 - accuracy: 0.8799\n",
      "Epoch 3/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4123 - accuracy: 0.8808\n",
      "Epoch 4/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4340 - accuracy: 0.8785\n",
      "Epoch 5/25\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4154 - accuracy: 0.8798\n",
      "Epoch 6/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4111 - accuracy: 0.8809\n",
      "Epoch 7/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4144 - accuracy: 0.8801\n",
      "Epoch 8/25\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4295 - accuracy: 0.8802\n",
      "Epoch 9/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4218 - accuracy: 0.8798\n",
      "Epoch 10/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4425 - accuracy: 0.8792\n",
      "Epoch 11/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4244 - accuracy: 0.8802\n",
      "Epoch 12/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4223 - accuracy: 0.8792\n",
      "Epoch 13/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4079 - accuracy: 0.8803\n",
      "Epoch 14/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4170 - accuracy: 0.8791\n",
      "Epoch 15/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4157 - accuracy: 0.8784\n",
      "Epoch 16/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4164 - accuracy: 0.8810\n",
      "Epoch 17/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4236 - accuracy: 0.8789\n",
      "Epoch 18/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4196 - accuracy: 0.8816\n",
      "Epoch 19/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4208 - accuracy: 0.8811\n",
      "Epoch 20/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4148 - accuracy: 0.8805\n",
      "Epoch 21/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4137 - accuracy: 0.8796\n",
      "Epoch 22/25\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4129 - accuracy: 0.8818\n",
      "Epoch 23/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4352 - accuracy: 0.8789\n",
      "Epoch 24/25\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4162 - accuracy: 0.8798\n",
      "Epoch 25/25\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4033 - accuracy: 0.8814\n"
=======
      "Epoch 1/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4815 - accuracy: 0.8554\n",
      "Epoch 2/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4883 - accuracy: 0.8546\n",
      "Epoch 3/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4975 - accuracy: 0.8547\n",
      "Epoch 4/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4682 - accuracy: 0.8590\n",
      "Epoch 5/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4711 - accuracy: 0.8586\n",
      "Epoch 6/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4749 - accuracy: 0.8595\n",
      "Epoch 7/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4731 - accuracy: 0.8583\n",
      "Epoch 8/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4785 - accuracy: 0.8582\n",
      "Epoch 9/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4695 - accuracy: 0.8595\n",
      "Epoch 10/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4646 - accuracy: 0.8592\n",
      "Epoch 11/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4720 - accuracy: 0.8600\n",
      "Epoch 12/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4724 - accuracy: 0.8604\n",
      "Epoch 13/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4628 - accuracy: 0.8624\n",
      "Epoch 14/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4707 - accuracy: 0.8605\n",
      "Epoch 15/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4510 - accuracy: 0.8626\n",
      "Epoch 16/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4592 - accuracy: 0.8635\n",
      "Epoch 17/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4719 - accuracy: 0.8597\n",
      "Epoch 18/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4637 - accuracy: 0.8619\n",
      "Epoch 19/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4559 - accuracy: 0.8644\n",
      "Epoch 20/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4642 - accuracy: 0.8639\n",
      "Epoch 21/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4604 - accuracy: 0.8639\n",
      "Epoch 22/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4712 - accuracy: 0.8631\n",
      "Epoch 23/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4525 - accuracy: 0.8628\n",
      "Epoch 24/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4607 - accuracy: 0.8645\n",
      "Epoch 25/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4588 - accuracy: 0.8644\n",
      "Epoch 26/100\n",
      "1350/1350 [==============================] - 6s 5ms/step - loss: 0.4532 - accuracy: 0.8653\n",
      "Epoch 27/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4546 - accuracy: 0.8653\n",
      "Epoch 28/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4764 - accuracy: 0.8652\n",
      "Epoch 29/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4550 - accuracy: 0.8657\n",
      "Epoch 30/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4507 - accuracy: 0.8684\n",
      "Epoch 31/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4559 - accuracy: 0.8653\n",
      "Epoch 32/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4473 - accuracy: 0.8690\n",
      "Epoch 33/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4391 - accuracy: 0.8689\n",
      "Epoch 34/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4467 - accuracy: 0.8692\n",
      "Epoch 35/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4512 - accuracy: 0.8682\n",
      "Epoch 36/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4533 - accuracy: 0.8654\n",
      "Epoch 37/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4487 - accuracy: 0.8668\n",
      "Epoch 38/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4609 - accuracy: 0.8672\n",
      "Epoch 39/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4364 - accuracy: 0.8691\n",
      "Epoch 40/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4443 - accuracy: 0.8698\n",
      "Epoch 41/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4412 - accuracy: 0.8688\n",
      "Epoch 42/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4519 - accuracy: 0.8686\n",
      "Epoch 43/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4547 - accuracy: 0.8692\n",
      "Epoch 44/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4402 - accuracy: 0.8713\n",
      "Epoch 45/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4558 - accuracy: 0.8682\n",
      "Epoch 46/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4366 - accuracy: 0.8707\n",
      "Epoch 47/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4496 - accuracy: 0.8697\n",
      "Epoch 48/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4535 - accuracy: 0.8700\n",
      "Epoch 49/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4363 - accuracy: 0.8711\n",
      "Epoch 50/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4387 - accuracy: 0.8704\n",
      "Epoch 51/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4536 - accuracy: 0.8688\n",
      "Epoch 52/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4472 - accuracy: 0.8699\n",
      "Epoch 53/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4373 - accuracy: 0.8708\n",
      "Epoch 54/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4357 - accuracy: 0.8706\n",
      "Epoch 55/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4399 - accuracy: 0.8713\n",
      "Epoch 56/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4390 - accuracy: 0.8732\n",
      "Epoch 57/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4331 - accuracy: 0.8736\n",
      "Epoch 58/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4376 - accuracy: 0.8713\n",
      "Epoch 59/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4359 - accuracy: 0.8716\n",
      "Epoch 60/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4424 - accuracy: 0.8705\n",
      "Epoch 61/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4456 - accuracy: 0.8718\n",
      "Epoch 62/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4297 - accuracy: 0.8756\n",
      "Epoch 63/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4419 - accuracy: 0.8713\n",
      "Epoch 64/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4414 - accuracy: 0.8713\n",
      "Epoch 65/100\n",
      "1350/1350 [==============================] - 7s 6ms/step - loss: 0.4418 - accuracy: 0.8718\n",
      "Epoch 66/100\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4337 - accuracy: 0.8735\n",
      "Epoch 67/100\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4300 - accuracy: 0.8734\n",
      "Epoch 68/100\n",
      "1350/1350 [==============================] - 7s 5ms/step - loss: 0.4511 - accuracy: 0.8720\n",
      "Epoch 69/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4393 - accuracy: 0.8749\n",
      "Epoch 70/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4267 - accuracy: 0.8741\n",
      "Epoch 71/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4308 - accuracy: 0.8741\n",
      "Epoch 72/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4327 - accuracy: 0.8755\n",
      "Epoch 73/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4324 - accuracy: 0.8748\n",
      "Epoch 74/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4309 - accuracy: 0.8732\n",
      "Epoch 75/100\n",
      "1350/1350 [==============================] - 5s 3ms/step - loss: 0.4377 - accuracy: 0.8735\n",
      "Epoch 76/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4358 - accuracy: 0.8717\n",
      "Epoch 77/100\n",
      "1350/1350 [==============================] - 4s 3ms/step - loss: 0.4380 - accuracy: 0.8722\n",
      "Epoch 78/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4358 - accuracy: 0.8731\n",
      "Epoch 79/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4377 - accuracy: 0.8729\n",
      "Epoch 80/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4555 - accuracy: 0.8732\n",
      "Epoch 81/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4359 - accuracy: 0.8747\n",
      "Epoch 82/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4271 - accuracy: 0.8744\n",
      "Epoch 83/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4356 - accuracy: 0.8740\n",
      "Epoch 84/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4347 - accuracy: 0.8750\n",
      "Epoch 85/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4244 - accuracy: 0.8770\n",
      "Epoch 86/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4304 - accuracy: 0.8757\n",
      "Epoch 87/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4261 - accuracy: 0.8730\n",
      "Epoch 88/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4393 - accuracy: 0.8749\n",
      "Epoch 89/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4258 - accuracy: 0.8755\n",
      "Epoch 90/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4319 - accuracy: 0.8728\n",
      "Epoch 91/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4282 - accuracy: 0.8743\n",
      "Epoch 92/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4373 - accuracy: 0.8744\n",
      "Epoch 93/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4435 - accuracy: 0.8746\n",
      "Epoch 94/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4317 - accuracy: 0.8738\n",
      "Epoch 95/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4221 - accuracy: 0.8746\n",
      "Epoch 96/100\n",
      "1350/1350 [==============================] - 6s 4ms/step - loss: 0.4320 - accuracy: 0.8739\n",
      "Epoch 97/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4219 - accuracy: 0.8751\n",
      "Epoch 98/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4137 - accuracy: 0.8767\n",
      "Epoch 99/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4272 - accuracy: 0.8762\n",
      "Epoch 100/100\n",
      "1350/1350 [==============================] - 5s 4ms/step - loss: 0.4219 - accuracy: 0.8757\n"
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
     ]
    },
    {
     "data": {
      "text/plain": [
<<<<<<< HEAD
       "<keras.callbacks.History at 0x7f911e982220>"
      ]
     },
     "execution_count": 220,
=======
       "<keras.callbacks.History at 0x7f8f6aee1fd0>"
      ]
     },
     "execution_count": 110,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
<<<<<<< HEAD
    "model.fit(X_train, y_train, verbose=1, epochs=25)"
=======
    "model.fit(X_train, y_train, verbose=1, epochs=100)"
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.484541\n",
      "Loss: 25.118053\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy: %f' % (accuracy))\n",
    "print('Loss: %f' % (loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of most popular twitter accounts\n",
    "most_popular_tweeters = {813286 : \"@barackobama\", 27260086 : \"@justinbieber\", 21447363 : \"@katyperry\", \n",
    "    79293791 : \"@rihanna\", 14230524 : \"@ladygaga\", 44196397 : \"@elonmusk\", 15846407 : \"@theellenshow\", \n",
    "    10228272 : \"@youtube\", 25365536 : \"@kimkardashian\", 23375688 : \"@selenagomez\", 428333 : \"@cnnbrk\", \n",
    "    783214 : \"@twitter\", 759251 : \"@cnn\", 16409683 : \"@britneyspears\", 11348282 : \"@nasa\", 21111883 : \"@ddlovato\", # 16\n",
    "    807095 : \"@nytimes\", 15485441 : \"@jimmyfallon\", 23083404 : \"@kingjames\", 5402612 : \"@bbcbreaking\", # 20\n",
    "    268414482 : \"@mileycyrus\", 105119490 : \"@niallofficial\", 96951800 : \"@fcbarcelona\", 627673190 : \"@championsleague\", \n",
    "    26257166 : \"@sportscenter\"}\n",
    "\n",
    "transpose_tweeters = {813286 : 0, 27260086 : 1, 21447363 : 2, \n",
    "    79293791 : 3, 14230524 : 4, 44196397 : 5, 15846407 : 6, \n",
    "    10228272 : 7, 25365536 : 8, 23375688 : 9, 428333 : 10, \n",
    "    783214 : 11, 759251 : 12, 16409683 : 13, 11348282 : 14, 21111883 : 15, # 16\n",
    "    807095 : 16, 15485441 : 17, 23083404 : 18, 5402612 : 19, # 20\n",
    "    268414482 : 20, 105119490 : 21, 96951800 : 22, 627673190 : 23, \n",
    "    26257166 : 24}\n",
    "\n",
    "\n",
    "reverse_transpose_tweeters = {0: 813286, 1: 27260086, 2: 21447363, \n",
    "    3:79293791, 4:14230524, 5:44196397, 6:15846407, \n",
    "    7:10228272, 8:25365536, 9:23375688, 10:428333, \n",
    "    11:783214, 12:759251, 13:16409683, 14:11348282, 15:21111883, # 16\n",
    "    16:807095, 17:15485441, 18:23083404, 19:5402612, # 20\n",
    "    20:268414482, 21:105119490, 22:96951800, 23:627673190, \n",
    "    24:26257166}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
=======
   "execution_count": 111,
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   "metadata": {},
   "outputs": [],
   "source": [
    "import cleantext as ct\n",
<<<<<<< HEAD
    "import recent_search_milo as rsm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter\n",
    "import pprint\n",
    "\n",
    "def predict_tweeter(tweet: str, model: Sequential) -> str:\n",
    "    '''\n",
    "    takes a tweet string from one of the twenty-five tweeters\n",
    "    returns a dictionary of the tweeters' handles and their model scores\n",
    "    prints the top three accounts and their scores\n",
    "    '''\n",
    "    \n",
=======
    "\n",
    "def predict_tweeter(tweet: str, model: Sequential) -> str:\n",
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
    "    # clean the tweet\n",
    "    cleaned = ct.clean_tweet(tweet)\n",
    "    # get vocabulary\n",
    "    vocab = ct.get_word_set()\n",
    "    # get counterizer\n",
    "    cv = CountVectorizer(vocabulary=vocab)\n",
    "\n",
    "    # get a word vector for it\n",
<<<<<<< HEAD
    "    wv = ct.get_word_vector(cleaned, cv)\n",
=======
    "    wv = ct.get_word_vector(tweet, cv, vocab)\n",
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
    "\n",
    "    # predict on the word vector\n",
    "    prediction = model.predict(wv)\n",
    "\n",
<<<<<<< HEAD
    "    # create a dictionary to hold the scores\n",
    "    pred_dict = dict.fromkeys(reverse_transpose_tweeters.keys())\n",
    "\n",
    "    # iterate through the result\n",
    "    for i in range(len(prediction[0])):\n",
    "        pred_dict[i] = prediction[0][i]\n",
    "\n",
    "    # add @ keys to the dictionary\n",
    "    for key in [k for k in pred_dict.keys()]:\n",
    "        k = reverse_transpose_tweeters[key]\n",
    "        k = most_popular_tweeters[k]\n",
    "        v = pred_dict.pop(key)\n",
    "\n",
    "        pred_dict.update({k : v})\n",
    "\n",
    "    # create a counter object of the prediction dictionary\n",
    "    cr = Counter(pred_dict)\n",
    "    # get the three most likely tweeters\n",
    "    highest = cr.most_common(5)\n",
    "\n",
    "    pprint.pprint(highest)\n",
    "\n",
    "    return pred_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@barackobama', 1.0), ('@justinbieber', 0.0), ('@katyperry', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from obama\n",
    "pd1 = predict_tweeter(\"Last week, I spoke with some of the young activists who have already recognized the problem \"\n",
    "    \"that disinformation poses to our communities and are doing their part to fix it. Take a look at our conversation:\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@selenagomez', 1.0),\n",
      " ('@rihanna', 2.9733737e-18),\n",
      " ('@jimmyfallon', 3.513508e-37)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from rihanna\n",
    "pd2 = predict_tweeter(\"Twake up and smell the billboard NYC!!!! \\n\\na wise woman once said,\" \n",
    "\" “smell however the f*ck you want” 💁🏿‍♀️, \\nand that wise woman is also here with great news… \"\n",
    "\"#FENTYPARFUM is finally back baby @ http://ri-hanna.io/fentyparfum\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@nytimes', 0.99999356),\n",
      " ('@mileycyrus', 3.3356807e-06),\n",
      " ('@ddlovato', 1.6588468e-06)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from elon musk\n",
    "pd3 = predict_tweeter(\"Since I’ve been asked a lot:\\nBuy stock in several companies that make products \"\n",
    "\"& services that *you* believe in.\\nOnly sell if you think their products & services are trending worse. \"\n",
    "\"Don’t panic when the market does.\\nThis will serve you well in the long-term.\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@cnnbrk', 1.0), ('@nytimes', 3.9457587e-10), ('@cnn', 1.3161707e-12)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from cnnbrk\n",
    "pd4 = predict_tweeter(\"A former Philadelphia police officer who fatally shot a 12-year-old boy in the back in March has been charged with first-degree murder, District Attorney Larry Krasner announced Monday.\", model)"
=======
    "    \n",
    "    \n",
    "\n"
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@jimmyfallon', 0.28683314),\n",
      " ('@kingjames', 0.26641595),\n",
      " ('@theellenshow', 0.15249594)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from rihanna\n",
    "pd5 = predict_tweeter(\"My very first #NationalHeroesDay as a National Hero of my country Barbados! 🇧🇧🇧🇧🇧🇧 What an absolute honor to be amongst such great men and women who have come before me and held this title in commitment to our nation!\", model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('@theellenshow', 0.7618925),\n",
      " ('@kingjames', 0.23275675),\n",
      " ('@jimmyfallon', 0.005350794)]\n"
     ]
    }
   ],
   "source": [
    "# tweet from lebron james\n",
    "pd6 = predict_tweeter(\"Wow it's been awhile since I've seen that footage. Weight of the world on the shoulders on #ThekidfromAKRON🤴🏾\", model)"
   ]
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> 0777df49d5c12a759bf95f8c48f8b3039a08921b
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f24fb1fbaf4de5d04d0c3b0d02603e78f9463bf4271da52643be3ab307db3b7d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
